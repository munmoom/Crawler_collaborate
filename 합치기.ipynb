{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "합치기.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/munmoom/Crawler_collaborate/blob/main/%ED%95%A9%EC%B9%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmvO6WGRY0Ae",
        "outputId": "f3565d50-e401-4c53-c266-e65684f93a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['제공기관', '수정일', '조회수', '다운로드']\n",
            "['한국언론진흥재단', '2021-08-25', '20049', '39972', '서울특별시 강동구', '2020-09-23', '2868', '765', '한국언론진흥재단', '2021-03-17', '3525', '1059', '한국언론진흥재단', '2021-03-17', '11669', '4456', '부산광역시 수영구', '2022-04-26', '1275', '191', '서울특별시 용산구', '2022-03-17', '248', '53', '강원도', '2022-03-28', '4791', '1320', '서울특별시 용산구', '2022-03-17', '2462', '770', '전라북도 고창군', '2022-04-01', '94', '41', '충청남도 계룡시', '2022-03-24', '82', '11']\n",
            "['한국언론진흥재단_뉴스빅데이터_메타데이터_코로나', '서울특별시 강동구_코로나동별현황', '한국언론진흥재단_코로나19이후국민의일상변화조사_포스트 코로나 사회에 대한 전망', '한국언론진흥재단_코로나19이후국민의일상변화조사_코로나19로 인한 감정 변화', '부산광역시 수영구_코로나 확진자 수', '서울특별시 용산구_코로나19사망자', '강원도_코로나19 확진자 현황', '서울특별시 용산구_코로나19확진자', '전라북도 고창군_코로나19 현황', '충청남도 계룡시_코로나19 확진자']\n"
          ]
        }
      ],
      "source": [
        "from urllib.request import urlopen\n",
        "url='https://www.data.go.kr/tcs/dss/selectDataSetList.do?dType=FILE&keyword=%EC%BD%94%EB%A1%9C%EB%82%98&detailKeyword=&publicDataPk=&recmSe=&detailText=&relatedKeyword=&commaNotInData=&commaAndData=&commaOrData=&must_not=&tabId=&dataSetCoreTf=&coreDataNm=&sort=_score&relRadio=&orgFullName=&orgFilter=&org=&orgSearch=&currentPage=1&perPage=10&brm=&instt=&svcType=&kwrdArray=&extsn=&coreDataNmArray=&pblonsipScopeCode='\n",
        "htmlData=urlopen(url).read()\n",
        "htmlData=htmlData.decode('utf8')\n",
        "from bs4 import BeautifulSoup as bs\n",
        "html=bs(htmlData,'html.parser')\n",
        "\n",
        "ul = html.select('#fileDataList > div.result-list > ul > li')\n",
        "\n",
        "who = []\n",
        "for item in ul:\n",
        "  num = item.find_all(\"span\", class_='tit')\n",
        "  who.append(num)\n",
        "\n",
        "import re\n",
        "ti=[]\n",
        "who = who[0]\n",
        "\n",
        "for a in range(4):\n",
        "    tit = who[a]\n",
        "    tit = str(tit)\n",
        "    tit = re.sub('<.+?>','', tit, a).strip()\n",
        "    ti.append(tit)\n",
        "\n",
        "string = ti[1]\n",
        "string = string[0:3]\n",
        "del ti[1]\n",
        "ti.insert(1, string)\n",
        "\n",
        "whole = []\n",
        "for item in ul:\n",
        "  num = item.find_all(\"span\", class_='data')\n",
        "  whole.append(num)\n",
        "\n",
        "\n",
        "import re\n",
        "list=[]\n",
        "for i in range(10):\n",
        "  ko = whole[i]\n",
        "  for a in range(4):\n",
        "    li = ko[a]\n",
        "    li = str(li)\n",
        "    li = re.sub('<.+?>','', li, a).strip()\n",
        "    list.append(li)\n",
        "\n",
        "for i in range(10):\n",
        "  k = 2+4*i-1\n",
        "  date = str(list[k])[0:10]\n",
        "  del list[k]\n",
        "  list.insert(k, date)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from urllib.request import urlopen\n",
        "url='https://www.data.go.kr/tcs/dss/selectDataSetList.do?dType=FILE&keyword=%EC%BD%94%EB%A1%9C%EB%82%98&detailKeyword=&publicDataPk=&recmSe=&detailText=&relatedKeyword=&commaNotInData=&commaAndData=&commaOrData=&must_not=&tabId=&dataSetCoreTf=&coreDataNm=&sort=_score&relRadio=&orgFullName=&orgFilter=&org=&orgSearch=&currentPage=1&perPage=10&brm=&instt=&svcType=&kwrdArray=&extsn=&coreDataNmArray=&pblonsipScopeCode='\n",
        "htmlData=urlopen(url).read()\n",
        "htmlData=htmlData.decode('utf8')\n",
        "from bs4 import BeautifulSoup as bs\n",
        "html=bs(htmlData,'html.parser')\n",
        "ul=html.select('#fileDataList > div.result-list > ul')\n",
        "head = []\n",
        "for item in ul:\n",
        "  title = item.find_all(\"span\", class_='title')\n",
        "  head.append(title)\n",
        "\n",
        "import re\n",
        "ABC=[]\n",
        "header = head[0]\n",
        "for i in range(10):\n",
        "  no=header[i]\n",
        "  no=str(no)\n",
        "  no = re.sub('<.+?>', '', no, i).strip()\n",
        "  for k in range(1,3):\n",
        "    no = re.sub('<.+?>', '', no, k).strip()\n",
        "\n",
        "  no = re.sub('<.+?>', '', no, 2).strip()\n",
        "  ABC.append(no)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(ti)\n",
        "print(list)\n",
        "print(ABC)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}